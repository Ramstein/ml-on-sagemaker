{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Kaggle data management api"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# !pip install kaggle # now download the api token and store it to /home/ec2-user/.kaggle/kaggle.json\r\n",
    "# !cd /home/ec2-user/SageMaker\r\n",
    "# !mkdir /home/ec2-user/.kaggle/\r\n",
    "# !mv /home/ec2-user/SageMaker/kaggle.json /home/ec2-user/.kaggle/kaggle.json\r\n",
    "# !chmod 600 /home/ec2-user/.kaggle/kaggle.json # for privacy\r\n",
    "!df -h --total  # get the harddisk info\r\n",
    "!nvcc --version  # Get the cuda version\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "devtmpfs        3.8G   76K  3.8G   1% /dev\n",
      "tmpfs           3.8G  4.0K  3.8G   1% /dev/shm\n",
      "/dev/nvme0n1p1   94G   76G   19G  81% /\n",
      "/dev/nvme1n1    985G  572G  373G  61% /home/ec2-user/SageMaker\n",
      "total           1.1T  647G  399G  62% -\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2018 NVIDIA Corporation\n",
      "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
      "Cuda compilation tools, release 10.0, V10.0.130\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# !git clone https://github.com/RamsteinWR/COVIDNet.git\r\n",
    "# !git clone https://github.com/ieee8023/covid-chestxray-dataset.git\r\n",
    "# !git clone https://github.com/agchung/Figure1-COVID-chestxray-dataset.git\r\n",
    "# !git clone https://github.com/agchung/Actualmed-COVID-chestxray-dataset.git\r\n",
    "\r\n",
    "# !rm -rf /home/ec2-user/SageMaker/COVIDNet"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# !pip install pydicom"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "%%time\r\n",
    "import os\r\n",
    "os.chdir(\"/home/ec2-user/SageMaker\")\r\n",
    "\r\n",
    "# Download the challenge data here \r\n",
    "# !kaggle competitions download -c rsna-pneumonia-detection-challenge\r\n",
    "# !unzip -o -q /home/ec2-user/SageMaker/rsna-pneumonia-detection-challenge.zip -d /home/ec2-user/SageMaker/PneumoniaData  #-q for quitely no verbose\r\n",
    "# !rm -rf /home/ec2-user/SageMaker/rsna-pneumonia-detection-challenge.zip"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 97 µs, sys: 14 µs, total: 111 µs\n",
      "Wall time: 117 µs\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing the authenication management"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "%%time\r\n",
    "import boto3\r\n",
    "import botocore\r\n",
    "from botocore.exceptions import ClientError\r\n",
    "from tqdm import tqdm\r\n",
    "import os \r\n",
    "import urllib.request\r\n",
    "import re\r\n",
    "import sagemaker\r\n",
    "from sagemaker import get_execution_role\r\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\r\n",
    "\r\n",
    "role = get_execution_role()\r\n",
    "\r\n",
    "bucket = \"covid19-pnemonia-dataset\"\r\n",
    "region_name=\"us-east-1\"\r\n",
    "aws_access_key_id = \"jdhaiuhadi\"\r\n",
    "aws_secret_access_key = \"hjafdvbujadh\"\r\n",
    "\r\n",
    "training_image = get_image_uri(boto3.Session().region_name, 'image-classification')\r\n",
    "\r\n",
    "def download(url):\r\n",
    "    filename = url.split(\"/\")[-1]\r\n",
    "    if not os.path.exists(filename):\r\n",
    "        urllib.request.urlretrieve(url, filename)\r\n",
    "\r\n",
    "def upload_to_s3(channel, file):\r\n",
    "    s3 = boto3.resource('s3',\r\n",
    "                             region_name=region_name,\r\n",
    "                             aws_access_key_id=aws_access_key_id,\r\n",
    "                             aws_secret_access_key=aws_secret_access_key)    \r\n",
    "    data = open(file, \"rb\")\r\n",
    "    key = channel + '/' + file\r\n",
    "    print(\"Uploading file {} to s3://{}/{}\".format(file, bucket, channel))\r\n",
    "    s3.Bucket(bucket).put_object(Key=key, Body=data)\r\n",
    "\r\n",
    "def upload_dir_to_s3(bucket, s3_folder, dir_to_upload):\r\n",
    "    s3_client = boto3.client('s3',\r\n",
    "                             region_name=region_name,\r\n",
    "                             aws_access_key_id=aws_access_key_id,\r\n",
    "                             aws_secret_access_key=aws_secret_access_key)\r\n",
    "    print(\"Uploading {} to s3://{}/{}\".format(dir_to_upload, bucket, s3_folder))\r\n",
    "    # enumerate local files recursively\r\n",
    "    for root, dirs, files in os.walk(dir_to_upload):\r\n",
    "        for filename in tqdm(files):\r\n",
    "            # construct the full local path\r\n",
    "            local_path = os.path.join(root, filename)\r\n",
    "            # construct the full Dropbox path\r\n",
    "            relative_path = os.path.relpath(local_path, dir_to_upload)\r\n",
    "            s3_path = os.path.join(s3_folder, relative_path).replace(\"\\\\\", \"/\")\r\n",
    "            try:\r\n",
    "                s3_client.head_object(Bucket=bucket, Key=s3_path)\r\n",
    "                print(\"Path found on S3! Deleting %s...\" % s3_path)\r\n",
    "                try:\r\n",
    "                    s3_client.delete_object(Bucket=bucket, Key=s3_path)\r\n",
    "                    try:\r\n",
    "#                         print(\"Uploading {} to s3://{}/{}\".format(dir_to_upload, bucket, s3_path)\r\n",
    "                        s3_client.upload_file(local_path, Bucket=bucket, Key=s3_path)\r\n",
    "                    except ClientError as e:\r\n",
    "                        logging.error(e)\r\n",
    "                except:\r\n",
    "                    print(\"Unable to delete from s3 %s...\" % s3_path)\r\n",
    "            except:\r\n",
    "                try:\r\n",
    "                    s3_client.upload_file(local_path, Bucket=bucket, Key=s3_path)\r\n",
    "                except ClientError as e:\r\n",
    "                    logging.error(e)\r\n",
    "    print(\"Upload completed successfully.\")\r\n",
    "    \r\n",
    "def download_dir(s3_folder, local_path, bucket=\"\"):\r\n",
    "    \"\"\"\r\n",
    "    params:\r\n",
    "    - s3_folder: pattern to match in s3\r\n",
    "    - local_path: local_path path to folder in which to place files\r\n",
    "    - bucket: s3 bucket with target contents\r\n",
    "    - client: initialized s3 client object\r\n",
    "    \"\"\"\r\n",
    "    client = boto3.client('s3', region_name=region_name)\r\n",
    "    keys = []\r\n",
    "    dirs = []\r\n",
    "    next_token = ''\r\n",
    "    base_kwargs = {\r\n",
    "        'Bucket': bucket,\r\n",
    "        'Prefix': s3_folder,\r\n",
    "    }\r\n",
    "    while next_token is not None:\r\n",
    "        kwargs = base_kwargs.copy()\r\n",
    "        if next_token != '':\r\n",
    "            kwargs.update({'ContinuationToken': next_token})\r\n",
    "        results = client.list_objects_v2(**kwargs)\r\n",
    "        contents = results.get('Contents')\r\n",
    "        for i in contents:\r\n",
    "            k = i.get('Key')\r\n",
    "            if k[-1] != '/':\r\n",
    "                keys.append(k)\r\n",
    "            else:\r\n",
    "                dirs.append(k)\r\n",
    "        next_token = results.get('NextContinuationToken')\r\n",
    "    for d in dirs:\r\n",
    "        dest_pathname = os.path.join(local_path, d)\r\n",
    "        if not os.path.exists(os.path.dirname(dest_pathname)):\r\n",
    "            os.makedirs(os.path.dirname(dest_pathname))\r\n",
    "    print(\"{} files found in {} directories. Downloading now...\".format(len(keys), len(dirs)))\r\n",
    "    for k in tqdm(keys):\r\n",
    "        dest_pathname = os.path.join(local_path, k)\r\n",
    "        if not os.path.exists(os.path.dirname(dest_pathname)):\r\n",
    "            os.makedirs(os.path.dirname(dest_pathname))\r\n",
    "        try:\r\n",
    "#             print(\"Downloading {}\".format(dest_pathname))\r\n",
    "            client.download_file(bucket, k, dest_pathname)\r\n",
    "        except botocore.exceptions.ClientError as e:\r\n",
    "            if e.response['Error']['Code'] == \"404\":\r\n",
    "                print(\"The object does not exist.\")\r\n",
    "            else:\r\n",
    "                raise\r\n",
    "    print(\"{} files downloaded successfully.\".format(len(keys)))\r\n",
    "    \r\n",
    "# download_dir(s3_folder='Covid19Radiography', local_path='/home/ec2-user/SageMaker/data', bucket=bucket)\r\n",
    "# !unzip -o -q /home/ec2-user/SageMaker/data/Covid19Radiography/COVID19RadiographyDatabase.zip -d /home/ec2-user/SageMaker/data/Covid19Radiography  #-q for quitely no verbose\r\n",
    "# !rm -rf /home/ec2-user/SageMaker/data/Covid19Radiography/COVID19RadiographyDatabase.zip\r\n",
    "\r\n",
    "# download_dir(s3_folder='COVIDNet-CXR_Large_Pretrained/', local_path='/home/ec2-user/SageMaker/data/COVIDNet-CXR-Large', bucket=bucket)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 633 ms, sys: 243 ms, total: 875 ms\n",
      "Wall time: 1.67 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='idg4c.1'></a>\n",
    "## Dependencies\n",
    "___\n",
    "### import packages and check SageMaker version"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import json\n",
    "# import torch\n",
    "import tarfile\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "# import torchvision as tv\n",
    "import pathlib                          # Path management tool (standard library)\n",
    "import subprocess                       # Runs shell commands via Python (standard library)\n",
    "import sagemaker                        # SageMaker Python SDK\n",
    "# from sagemaker.pytorch import PyTorch   # PyTorch Estimator for TensorFlow"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random \n",
    "from shutil import copyfile\n",
    "import pydicom as dicom\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydicom'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6f0831fd704c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mshutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopyfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydicom\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdicom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydicom'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# set parameters here\n",
    "savepath = '/home/ec2-user/SageMaker/data'\n",
    "seed = 0\n",
    "np.random.seed(seed) # Reset the seed so all runs are the same.\n",
    "random.seed(seed)\n",
    "MAXVAL = 255  # Range [0 255]\n",
    "\n",
    "# path to covid-19 dataset from https://github.com/ieee8023/covid-chestxray-dataset\n",
    "cohen_imgpath = '/home/ec2-user/SageMaker/covid-chestxray-dataset/images' \n",
    "cohen_csvpath = '/home/ec2-user/SageMaker/covid-chestxray-dataset/metadata.csv'\n",
    "\n",
    "# path to covid-19 dataset from https://github.com/agchung/Figure1-COVID-chestxray-dataset\n",
    "fig1_imgpath = '/home/ec2-user/SageMaker/Figure1-COVID-chestxray-dataset/images'\n",
    "fig1_csvpath = '/home/ec2-user/SageMaker/Figure1-COVID-chestxray-dataset/metadata.csv'\n",
    "\n",
    "# path to covid-19 dataset from https://github.com/agchung/Actualmed-COVID-chestxray-dataset\n",
    "actmed_imgpath = '/home/ec2-user/SageMaker/Actualmed-COVID-chestxray-dataset/images'\n",
    "actmed_csvpath = '/home/ec2-user/SageMaker/Actualmed-COVID-chestxray-dataset/metadata.csv'\n",
    "\n",
    "# path to covid-19 dataset from https://www.kaggle.com/tawsifurrahman/covid19-radiography-database\n",
    "sirm_imgpath = '/home/ec2-user/SageMaker/data/Covid19Radiography/COVID-19'\n",
    "sirm_csvpath = '/home/ec2-user/SageMaker/data/Covid19Radiography/COVID-19.metadata.csv'\n",
    "\n",
    "# path to https://www.kaggle.com/c/rsna-pneumonia-detection-challenge\n",
    "rsna_datapath = '/home/ec2-user/SageMaker/PneumoniaData'\n",
    "# get all the normal from here\n",
    "rsna_csvname = 'stage_2_detailed_class_info.csv' \n",
    "# get all the 1s from here since 1 indicate pneumonia\n",
    "# found that images that aren't pneunmonia and also not normal are classified as 0s\n",
    "rsna_csvname2 = 'stage_2_train_labels.csv' \n",
    "rsna_imgpath = 'train_dicoms'\n",
    "\n",
    "# parameters for COVIDx dataset\n",
    "train = []\n",
    "test = []\n",
    "test_count = {'normal': 0, 'pneumonia': 0, 'COVID-19': 0}\n",
    "train_count = {'normal': 0, 'pneumonia': 0, 'COVID-19': 0}\n",
    "\n",
    "mapping = dict()\n",
    "mapping['COVID-19'] = 'COVID-19'\n",
    "mapping['SARS'] = 'pneumonia'\n",
    "mapping['MERS'] = 'pneumonia'\n",
    "mapping['Streptococcus'] = 'pneumonia'\n",
    "mapping['Klebsiella'] = 'pneumonia'\n",
    "mapping['Chlamydophila'] = 'pneumonia'\n",
    "mapping['Legionella'] = 'pneumonia'\n",
    "mapping['E.Coli'] = 'pneumonia'\n",
    "mapping['Normal'] = 'normal'\n",
    "mapping['Lung Opacity'] = 'pneumonia'\n",
    "mapping['1'] = 'pneumonia'\n",
    "\n",
    "# train/test split\n",
    "split = 0.1\n",
    "\n",
    "# to avoid duplicates\n",
    "patient_imgpath = {}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# adapted from https://github.com/mlmed/torchxrayvision/blob/master/torchxrayvision/datasets.py#L814\n",
    "cohen_csv = pd.read_csv(cohen_csvpath, nrows=None)\n",
    "#idx_pa = csv[\"view\"] == \"PA\"  # Keep only the PA view\n",
    "views = [\"PA\", \"AP\", \"AP Supine\", \"AP semi erect\", \"AP erect\"]\n",
    "cohen_idx_keep = cohen_csv.view.isin(views)\n",
    "cohen_csv = cohen_csv[cohen_idx_keep]\n",
    "\n",
    "fig1_csv = pd.read_csv(fig1_csvpath, encoding='ISO-8859-1', nrows=None)\n",
    "actmed_csv = pd.read_csv(actmed_csvpath, nrows=None)\n",
    "\n",
    "sirm_csv = pd.read_csv(sirm_csvpath)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get non-COVID19 viral, bacteria, and COVID-19 infections from covid-chestxray-dataset, figure1 and actualmed\n",
    "# stored as patient id, image filename and label\n",
    "filename_label = {'normal': [], 'pneumonia': [], 'COVID-19': []}\n",
    "count = {'normal': 0, 'pneumonia': 0, 'COVID-19': 0}\n",
    "covid_ds = {'cohen': [], 'fig1': [], 'actmed': [], 'sirm': []}\n",
    "\n",
    "for index, row in cohen_csv.iterrows():\n",
    "    f = row['finding'].split('/')[-1] # take final finding in hierarchy, for the case of COVID-19, ARDS\n",
    "    if f in mapping: # \n",
    "        count[mapping[f]] += 1\n",
    "        entry = [str(row['patientid']), row['filename'], mapping[f], 'cohen']\n",
    "        filename_label[mapping[f]].append(entry)\n",
    "        if mapping[f] == 'COVID-19':\n",
    "            covid_ds['cohen'].append(str(row['patientid']))\n",
    "        \n",
    "for index, row in fig1_csv.iterrows():\n",
    "    if not str(row['finding']) == 'nan':\n",
    "        f = row['finding'].split(',')[0] # take the first finding\n",
    "        if f in mapping: # \n",
    "            count[mapping[f]] += 1\n",
    "            if os.path.exists(os.path.join(fig1_imgpath, row['patientid'] + '.jpg')):\n",
    "                entry = [row['patientid'], row['patientid'] + '.jpg', mapping[f], 'fig1']\n",
    "            elif os.path.exists(os.path.join(fig1_imgpath, row['patientid'] + '.png')):\n",
    "                entry = [row['patientid'], row['patientid'] + '.png', mapping[f], 'fig1']\n",
    "            filename_label[mapping[f]].append(entry)\n",
    "            if mapping[f] == 'COVID-19':\n",
    "                covid_ds['fig1'].append(row['patientid'])\n",
    "\n",
    "for index, row in actmed_csv.iterrows():\n",
    "    if not str(row['finding']) == 'nan':\n",
    "        f = row['finding'].split(',')[0]\n",
    "        if f in mapping:\n",
    "            count[mapping[f]] += 1\n",
    "            entry = [row['patientid'], row['imagename'], mapping[f], 'actmed']\n",
    "            filename_label[mapping[f]].append(entry)\n",
    "            if mapping[f] == 'COVID-19':\n",
    "                covid_ds['actmed'].append(row['patientid'])\n",
    "    \n",
    "sirm = set(sirm_csv['URL'])\n",
    "cohen = set(cohen_csv['url'])\n",
    "discard = ['100', '101', '102', '103', '104', '105', \n",
    "           '110', '111', '112', '113', '122', '123', \n",
    "           '124', '125', '126', '217']\n",
    "\n",
    "for idx, row in sirm_csv.iterrows():\n",
    "    patientid = row['FILE NAME']\n",
    "    if row['URL'] not in cohen and patientid[patientid.find('(')+1:patientid.find(')')] not in discard:\n",
    "        count[mapping['COVID-19']] += 1\n",
    "        imagename = patientid + '.' + row['FORMAT'].lower()\n",
    "        if not os.path.exists(os.path.join(sirm_imgpath, imagename)):\n",
    "            imagename = patientid.split('(')[0] + ' ('+ patientid.split('(')[1] + '.' + row['FORMAT'].lower()\n",
    "        entry = [patientid, imagename, mapping['COVID-19'], 'sirm']\n",
    "        filename_label[mapping['COVID-19']].append(entry)\n",
    "        covid_ds['sirm'].append(patientid)\n",
    "    \n",
    "print('Data distribution from covid datasets:')\n",
    "print(count)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !cp -a -r /home/ec2-user/SageMaker/data/images /home/ec2-user/SageMaker/covid-chestxray-dataset/images"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# add covid-chestxray-dataset, figure1 and actualmed into COVIDx dataset\n",
    "# since these datasets don't have test dataset, split into train/test by patientid\n",
    "# for covid-chestxray-dataset:\n",
    "# patient 8 is used as non-COVID19 viral test\n",
    "# patient 31 is used as bacterial test\n",
    "# patients 19, 20, 36, 42, 86 are used as COVID-19 viral test\n",
    "# for figure 1:\n",
    "# patients 24, 25, 27, 29, 30, 32, 33, 36, 37, 38\n",
    "\n",
    "ds_imgpath = {'cohen': cohen_imgpath, 'fig1': fig1_imgpath, 'actmed': actmed_imgpath, 'sirm': sirm_imgpath}\n",
    "\n",
    "for key in filename_label.keys():\n",
    "    arr = np.array(filename_label[key])\n",
    "    if arr.size == 0:\n",
    "        continue\n",
    "    # split by patients\n",
    "    # num_diff_patients = len(np.unique(arr[:,0]))\n",
    "    # num_test = max(1, round(split*num_diff_patients))\n",
    "    # select num_test number of random patients\n",
    "    # random.sample(list(arr[:,0]), num_test)\n",
    "    if key == 'pneumonia':\n",
    "        test_patients = ['8', '31']\n",
    "    elif key == 'COVID-19':\n",
    "        test_patients = ['19', '20', '36', '42', '86', \n",
    "                         '94', '97', '117', '132', \n",
    "                         '138', '144', '150', '163', '169', '174', '175', '179', '190', '191'\n",
    "                         'COVID-00024', 'COVID-00025', 'COVID-00026', 'COVID-00027', 'COVID-00029',\n",
    "                         'COVID-00030', 'COVID-00032', 'COVID-00033', 'COVID-00035', 'COVID-00036',\n",
    "                         'COVID-00037', 'COVID-00038',\n",
    "                         'ANON24', 'ANON45', 'ANON126', 'ANON106', 'ANON67',\n",
    "                         'ANON153', 'ANON135', 'ANON44', 'ANON29', 'ANON201', \n",
    "                         'ANON191', 'ANON234', 'ANON110', 'ANON112', 'ANON73', \n",
    "                         'ANON220', 'ANON189', 'ANON30', 'ANON53', 'ANON46',\n",
    "                         'ANON218', 'ANON240', 'ANON100', 'ANON237', 'ANON158',\n",
    "                         'ANON174', 'ANON19', 'ANON195',\n",
    "                         'COVID-19(119)', 'COVID-19(87)', 'COVID-19(70)', 'COVID-19(94)', \n",
    "                         'COVID-19(215)', 'COVID-19(77)', 'COVID-19(213)', 'COVID-19(81)', \n",
    "                         'COVID-19(216)', 'COVID-19(72)', 'COVID-19(106)', 'COVID-19(131)', \n",
    "                         'COVID-19(107)', 'COVID-19(116)', 'COVID-19(95)', 'COVID-19(214)', \n",
    "                         'COVID-19(129)']\n",
    "    else: \n",
    "        test_patients = []\n",
    "    print('Key: ', key)\n",
    "    print('Test patients: ', test_patients)\n",
    "    # go through all the patients\n",
    "    for patient in arr:\n",
    "        if patient[0] not in patient_imgpath:\n",
    "            patient_imgpath[patient[0]] = [patient[1]]\n",
    "        else:\n",
    "            if patient[1] not in patient_imgpath[patient[0]]:\n",
    "                patient_imgpath[patient[0]].append(patient[1])\n",
    "            else:\n",
    "                continue  # skip since image has already been written\n",
    "        if patient[0] in test_patients:\n",
    "            if patient[3] == 'sirm':\n",
    "                image = cv2.imread(os.path.join(ds_imgpath[patient[3]], patient[1]))\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                patient[1] = patient[1].replace(' ', '')\n",
    "                cv2.imwrite(os.path.join(savepath, 'test', patient[1]), gray)\n",
    "            else:\n",
    "                copyfile(os.path.join(ds_imgpath[patient[3]], patient[1]), os.path.join(savepath, 'test', patient[1]))\n",
    "            test.append(patient)\n",
    "            test_count[patient[2]] += 1\n",
    "        else:\n",
    "            if patient[3] == 'sirm':\n",
    "                image = cv2.imread(os.path.join(ds_imgpath[patient[3]], patient[1]))\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                patient[1] = patient[1].replace(' ', '')\n",
    "                cv2.imwrite(os.path.join(savepath, 'train', patient[1]), gray)\n",
    "            else:\n",
    "                copyfile(os.path.join(ds_imgpath[patient[3]], patient[1]), os.path.join(savepath, 'train', patient[1]))\n",
    "            train.append(patient)\n",
    "            train_count[patient[2]] += 1\n",
    "\n",
    "print('test count: ', test_count)\n",
    "print('train count: ', train_count)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# add normal and rest of pneumonia cases from https://www.kaggle.com/c/rsna-pneumonia-detection-challenge\n",
    "csv_normal = pd.read_csv(os.path.join(rsna_datapath, rsna_csvname), nrows=None)\n",
    "csv_pneu = pd.read_csv(os.path.join(rsna_datapath, rsna_csvname2), nrows=None)\n",
    "patients = {'normal': [], 'pneumonia': []}\n",
    "\n",
    "for index, row in csv_normal.iterrows():\n",
    "    if row['class'] == 'Normal':\n",
    "        patients['normal'].append(row['patientId'])\n",
    "\n",
    "for index, row in csv_pneu.iterrows():\n",
    "    if int(row['Target']) == 1:\n",
    "        patients['pneumonia'].append(row['patientId'])\n",
    "\n",
    "for key in patients.keys():\n",
    "    arr = np.array(patients[key])\n",
    "    if arr.size == 0:\n",
    "        continue\n",
    "    # split by patients \n",
    "    # num_diff_patients = len(np.unique(arr))\n",
    "    # num_test = max(1, round(split*num_diff_patients))\n",
    "    test_patients = np.load('rsna_test_patients_{}.npy'.format(key)) # random.sample(list(arr), num_test), download the .npy files from the repo.\n",
    "    # np.save('rsna_test_patients_{}.npy'.format(key), np.array(test_patients))\n",
    "    for patient in tqdm(arr):\n",
    "        if patient not in patient_imgpath:\n",
    "            patient_imgpath[patient] = [patient]\n",
    "        else:\n",
    "            continue  # skip since image has already been written\n",
    "                \n",
    "        ds = dicom.dcmread(os.path.join(rsna_datapath, rsna_imgpath, patient + '.dcm'))\n",
    "        pixel_array_numpy = ds.pixel_array\n",
    "        imgname = patient + '.png'\n",
    "        if patient in test_patients:\n",
    "            cv2.imwrite(os.path.join(savepath, 'test', imgname), pixel_array_numpy)\n",
    "            test.append([patient, imgname, key, 'rsna'])\n",
    "            test_count[key] += 1\n",
    "        else:\n",
    "            cv2.imwrite(os.path.join(savepath, 'train', imgname), pixel_array_numpy)\n",
    "            train.append([patient, imgname, key, 'rsna'])\n",
    "            train_count[key] += 1\n",
    "\n",
    "print('test count: ', test_count)\n",
    "print('train count: ', train_count)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# final stats\n",
    "print('Final stats')\n",
    "print('Train count: ', train_count)\n",
    "print('Test count: ', test_count)\n",
    "print('Total length of train: ', len(train))\n",
    "print('Total length of test: ', len(test))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# export to train and test csv\n",
    "# format as patientid, filename, label, separated by a space\n",
    "train_file = open(\"/home/ec2-user/SageMaker/data/train_split.txt\",'w') \n",
    "for sample in train:\n",
    "    if len(sample) == 4:\n",
    "        info = str(sample[0]) + ' ' + sample[1] + ' ' + sample[2] + ' ' + sample[3] + '\\n'\n",
    "    else:\n",
    "        info = str(sample[0]) + ' ' + sample[1] + ' ' + sample[2] + '\\n'\n",
    "    train_file.write(info)\n",
    "\n",
    "train_file.close()\n",
    "\n",
    "test_file = open(\"/home/ec2-user/SageMaker/data/test_split.txt\", 'w')\n",
    "for sample in test:\n",
    "    if len(sample) == 4:\n",
    "        info = str(sample[0]) + ' ' + sample[1] + ' ' + sample[2] + ' ' + sample[3] + '\\n'\n",
    "    else:\n",
    "        info = str(sample[0]) + ' ' + sample[1] + ' ' + sample[2] + '\\n'\n",
    "    test_file.write(info)\n",
    "\n",
    "test_file.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}